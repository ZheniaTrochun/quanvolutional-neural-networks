{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32152,"status":"ok","timestamp":1708129386159,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"_DzWy2QT7t3n","outputId":"2d3cec4a-2499-42a4-b30d-7f6b7596de7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu121)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.48.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.48.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"]}],"source":["# !pip install torch==2.2\n","!pip install torch\n","!pip install torchvision\n","!pip install seaborn\n","!pip install numpy\n","!pip install matplotlib\n","# !pip install torchsummary\n","# !pip install torchview\n","# !pip install graphviz\n","# !pip install torchviz\n","!pip install pandas\n","# !pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7215,"status":"ok","timestamp":1708129393373,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"aIAEtl027t3p"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torch.utils.data import random_split\n","import seaborn as sns\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":184122,"status":"ok","timestamp":1708129577493,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"ImXF4sXm8GY0","outputId":"94903306-9c60-43fe-948f-7b5c32f86802"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708129577493,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"mvWm7omZ7t3p","outputId":"5ad0cd7b-df4f-4c76-e542-19eeb569a015"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708129577494,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"_D0laDM27t3p"},"outputs":[],"source":["BATCH_SIZE = 64\n","num_epoch = 10\n","learning_rate = 1e-4\n","class_size = 10"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1708129577494,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"uRpwm0-lwTcJ"},"outputs":[],"source":["transform_train = transforms.Compose([transforms.Resize((224, 224)),\n","                                      transforms.RandomHorizontalFlip(p=0.7)])\n","\n","transform_test = transforms.Compose([transforms.Resize((224, 224))])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":446,"status":"ok","timestamp":1708129577938,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"MHGjZijytuHu","outputId":"6b7c1a78-7b88-4656-e067-bf1a1ffcc7ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["QNN_TRAIN_CPU_hurricane_W4_X_S0_E10000_s1.npy\t  QNN_TRAIN_CPU_hurricane_W4_XY_S0_E5000_s1.npy\n","QNN_TRAIN_CPU_hurricane_W4_X_S0_E10000_s2.npy\t  QNN_TRAIN_CPU_hurricane_W4_XY_S5000_E10000_s1.npy\n","QNN_TRAIN_CPU_hurricane_W4_X_S0_E5000_s1.npy\t  raw_hurricane_dataset\n","QNN_TRAIN_CPU_hurricane_W4_X_S5000_E10000_s1.npy  train_another_labels.npy\n","QNN_TRAIN_CPU_hurricane_W4_XY_S0_E10000_s1.npy\n"]}],"source":["!ls /content/drive/MyDrive/hurricane_damage/"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":134377,"status":"ok","timestamp":1708129712314,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"8p_JL-OuKW9C"},"outputs":[],"source":["q_train_images = np.load(\"/content/drive/MyDrive/hurricane_damage/QNN_TRAIN_CPU_hurricane_W4_XY_S0_E10000_s1.npy\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12294,"status":"ok","timestamp":1708129724604,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"oi4WFny8PMIX","outputId":"c334ae8d-50f5-498a-a970-e5a1dab90647"},"outputs":[{"name":"stdout","output_type":"stream","text":["shape of raw quantum train data: (10000, 127, 127, 3, 4)\n","shape of quantum train data: (40000, 3, 127, 127)\n"]}],"source":["print(f'shape of raw quantum train data: {q_train_images.shape}')\n","train_output_shape = (4 * 10000, 127, 127, 3)\n","q_train_images = np.transpose(q_train_images, (4, 0, 1, 2, 3))\n","q_train_images = np.reshape(q_train_images, train_output_shape)\n","q_train_images = np.transpose(q_train_images, (0, 3, 1, 2))\n","print(f'shape of quantum train data: {q_train_images.shape}')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":27538,"status":"ok","timestamp":1708129752134,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"FiUuQoX27t3p"},"outputs":[],"source":["torch.manual_seed(2024)\n","\n","train_ref = torchvision.datasets.ImageFolder(\"/content/drive/MyDrive/hurricane_damage/raw_hurricane_dataset/train_another/\", transform=transforms.ToTensor())\n","\n","train_loader_ref = DataLoader(train_ref, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":469,"status":"ok","timestamp":1708129752601,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"ShpaIvJXZmwq","outputId":"03e2d44c-70ce-4d3c-f761-981f083425a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["(10000,)\n"]}],"source":["labels = np.load(\"/content/drive/MyDrive/hurricane_damage/train_another_labels.npy\")\n","print(labels.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708129752601,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"dkxcnIE2Z-PN","outputId":"ad03f90a-81cc-4937-f298-4bce74ed8cb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([40000])\n"]}],"source":["transformed_labels = torch.Tensor(labels.tolist() * 4).to(torch.int64)\n","print(transformed_labels.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1633,"status":"ok","timestamp":1708129754232,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"6ob4ZFCaakTg"},"outputs":[],"source":["train_dataset = TensorDataset(torch.Tensor(q_train_images), transformed_labels)\n","\n","val_size = 8000\n","\n","train_size = len(train_dataset) - val_size\n","\n","train, val = random_split(train_dataset, [train_size, val_size])\n","train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=False)\n","test_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360,"output_embedded_package_id":"1JervxH_KSPmnUqC1nGTm5FZTGNR4EZzC"},"executionInfo":{"elapsed":10117,"status":"ok","timestamp":1708129764346,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"RPtLRVK4GPUj","outputId":"f8e09da5-086c-48cf-8ba2-e6d2ba785dee"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","from torchvision.utils import make_grid\n","\n","for images, labels in train_loader:\n","    print('shape: ', images.shape)\n","    print(labels.tolist())\n","    plt.figure(figsize=(100, 100))\n","    plt.axis('off')\n","    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n","    break"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":503,"status":"ok","timestamp":1708129764846,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"wsBYgxGc7t3q","outputId":"d3e7ed1e-efc8-4308-acac-8c568355cb1d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n","100%|██████████| 82.7M/82.7M [00:00<00:00, 171MB/s]\n"]}],"source":["from torchvision import models\n","\n","model = models.efficientnet_v2_s(pretrained=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1708129764847,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"TYGwPH7c7t3q","outputId":"b0414ed2-efe4-4114-99de-d07abfd894e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["EfficientNet(\n","  (features): Sequential(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n","      )\n","      (1): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.005, mode=row)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.01, mode=row)\n","      )\n","      (1): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n","      )\n","      (2): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.02, mode=row)\n","      )\n","      (3): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.030000000000000006, mode=row)\n","      )\n","      (1): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.035, mode=row)\n","      )\n","      (2): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n","      )\n","      (3): FusedMBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.045, mode=row)\n","      )\n","    )\n","    (4): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.05500000000000001, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.06000000000000001, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.065, mode=row)\n","      )\n","      (4): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.07, mode=row)\n","      )\n","      (5): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n","            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.075, mode=row)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n","            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.085, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.09, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.095, mode=row)\n","      )\n","      (4): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n","      )\n","      (5): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.10500000000000001, mode=row)\n","      )\n","      (6): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.11000000000000001, mode=row)\n","      )\n","      (7): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.11500000000000002, mode=row)\n","      )\n","      (8): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.12000000000000002, mode=row)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n","            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n","      )\n","      (1): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.13, mode=row)\n","      )\n","      (2): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.135, mode=row)\n","      )\n","      (3): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.14, mode=row)\n","      )\n","      (4): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.14500000000000002, mode=row)\n","      )\n","      (5): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.15, mode=row)\n","      )\n","      (6): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.155, mode=row)\n","      )\n","      (7): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n","      )\n","      (8): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.165, mode=row)\n","      )\n","      (9): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.17, mode=row)\n","      )\n","      (10): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.175, mode=row)\n","      )\n","      (11): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.18, mode=row)\n","      )\n","      (12): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.185, mode=row)\n","      )\n","      (13): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.19, mode=row)\n","      )\n","      (14): MBConv(\n","        (block): Sequential(\n","          (0): Conv2dNormActivation(\n","            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (1): Conv2dNormActivation(\n","            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n","            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","            (2): SiLU(inplace=True)\n","          )\n","          (2): SqueezeExcitation(\n","            (avgpool): AdaptiveAvgPool2d(output_size=1)\n","            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n","            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n","            (activation): SiLU(inplace=True)\n","            (scale_activation): Sigmoid()\n","          )\n","          (3): Conv2dNormActivation(\n","            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (stochastic_depth): StochasticDepth(p=0.195, mode=row)\n","      )\n","    )\n","    (7): Conv2dNormActivation(\n","      (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): SiLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.2, inplace=True)\n","    (1): Linear(in_features=1280, out_features=1000, bias=True)\n","  )\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708129764847,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"H28eERwC7t3r"},"outputs":[],"source":["input_last_year = model.classifier[1].in_features\n","model.classifier[1] = nn.Linear(input_last_year, 2)\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708129764847,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"RLZih5fa7t3r"},"outputs":[],"source":["epoch_loss_history = []\n","epoch_acc_history = []"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1162287,"status":"ok","timestamp":1708130927124,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"EnnQpTMx7t3r","outputId":"dbf6b6fc-3fc2-41d6-eb1a-ae668f9a6e9e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["epoch 1/10, step: 10/500.0: loss = 0.53340, acc = 82.81\n","epoch 1/10, step: 20/500.0: loss = 0.29123, acc = 95.31\n","epoch 1/10, step: 30/500.0: loss = 0.20126, acc = 90.62\n","epoch 1/10, step: 40/500.0: loss = 0.15045, acc = 92.19\n","epoch 1/10, step: 50/500.0: loss = 0.11374, acc = 96.88\n","epoch 1/10, step: 60/500.0: loss = 0.12089, acc = 96.88\n","epoch 1/10, step: 70/500.0: loss = 0.09026, acc = 96.88\n","epoch 1/10, step: 80/500.0: loss = 0.14775, acc = 93.75\n","epoch 1/10, step: 90/500.0: loss = 0.08194, acc = 95.31\n","epoch 1/10, step: 100/500.0: loss = 0.03464, acc = 98.44\n","epoch 1/10, step: 110/500.0: loss = 0.07404, acc = 96.88\n","epoch 1/10, step: 120/500.0: loss = 0.03462, acc = 100.00\n","epoch 1/10, step: 130/500.0: loss = 0.04614, acc = 98.44\n","epoch 1/10, step: 140/500.0: loss = 0.08070, acc = 98.44\n","epoch 1/10, step: 150/500.0: loss = 0.09168, acc = 95.31\n","epoch 1/10, step: 160/500.0: loss = 0.06464, acc = 98.44\n","epoch 1/10, step: 170/500.0: loss = 0.01900, acc = 100.00\n","epoch 1/10, step: 180/500.0: loss = 0.05046, acc = 96.88\n","epoch 1/10, step: 190/500.0: loss = 0.07365, acc = 96.88\n","epoch 1/10, step: 200/500.0: loss = 0.11542, acc = 93.75\n","epoch 1/10, step: 210/500.0: loss = 0.11715, acc = 93.75\n","epoch 1/10, step: 220/500.0: loss = 0.07083, acc = 98.44\n","epoch 1/10, step: 230/500.0: loss = 0.05223, acc = 96.88\n","epoch 1/10, step: 240/500.0: loss = 0.02675, acc = 100.00\n","epoch 1/10, step: 250/500.0: loss = 0.07271, acc = 95.31\n","epoch 1/10, step: 260/500.0: loss = 0.04524, acc = 98.44\n","epoch 1/10, step: 270/500.0: loss = 0.01931, acc = 98.44\n","epoch 1/10, step: 280/500.0: loss = 0.01913, acc = 100.00\n","epoch 1/10, step: 290/500.0: loss = 0.03202, acc = 98.44\n","epoch 1/10, step: 300/500.0: loss = 0.05996, acc = 96.88\n","epoch 1/10, step: 310/500.0: loss = 0.05526, acc = 95.31\n","epoch 1/10, step: 320/500.0: loss = 0.02282, acc = 100.00\n","epoch 1/10, step: 330/500.0: loss = 0.00564, acc = 100.00\n","epoch 1/10, step: 340/500.0: loss = 0.03915, acc = 98.44\n","epoch 1/10, step: 350/500.0: loss = 0.04362, acc = 98.44\n","epoch 1/10, step: 360/500.0: loss = 0.03855, acc = 98.44\n","epoch 1/10, step: 370/500.0: loss = 0.02089, acc = 100.00\n","epoch 1/10, step: 380/500.0: loss = 0.07307, acc = 96.88\n","epoch 1/10, step: 390/500.0: loss = 0.10199, acc = 93.75\n","epoch 1/10, step: 400/500.0: loss = 0.02385, acc = 100.00\n","epoch 1/10, step: 410/500.0: loss = 0.04978, acc = 98.44\n","epoch 1/10, step: 420/500.0: loss = 0.09531, acc = 95.31\n","epoch 1/10, step: 430/500.0: loss = 0.07067, acc = 96.88\n","epoch 1/10, step: 440/500.0: loss = 0.04877, acc = 98.44\n","epoch 1/10, step: 450/500.0: loss = 0.08500, acc = 96.88\n","epoch 1/10, step: 460/500.0: loss = 0.00524, acc = 100.00\n","epoch 1/10, step: 470/500.0: loss = 0.03133, acc = 98.44\n","epoch 1/10, step: 480/500.0: loss = 0.00839, acc = 100.00\n","epoch 1/10, step: 490/500.0: loss = 0.02909, acc = 98.44\n","epoch 1/10, step: 500/500.0: loss = 0.00728, acc = 100.00\n","epoch 1/10, val accuracy = 98.32%. Correct 7866 out of 8000 samples\n","epoch 2/10, step: 10/500.0: loss = 0.01549, acc = 100.00\n","epoch 2/10, step: 20/500.0: loss = 0.00468, acc = 100.00\n","epoch 2/10, step: 30/500.0: loss = 0.01472, acc = 98.44\n","epoch 2/10, step: 40/500.0: loss = 0.00614, acc = 100.00\n","epoch 2/10, step: 50/500.0: loss = 0.04825, acc = 98.44\n","epoch 2/10, step: 60/500.0: loss = 0.00704, acc = 100.00\n","epoch 2/10, step: 70/500.0: loss = 0.00370, acc = 100.00\n","epoch 2/10, step: 80/500.0: loss = 0.01920, acc = 98.44\n","epoch 2/10, step: 90/500.0: loss = 0.01052, acc = 100.00\n","epoch 2/10, step: 100/500.0: loss = 0.00226, acc = 100.00\n","epoch 2/10, step: 110/500.0: loss = 0.00056, acc = 100.00\n","epoch 2/10, step: 120/500.0: loss = 0.00277, acc = 100.00\n","epoch 2/10, step: 130/500.0: loss = 0.00495, acc = 100.00\n","epoch 2/10, step: 140/500.0: loss = 0.00260, acc = 100.00\n","epoch 2/10, step: 150/500.0: loss = 0.00195, acc = 100.00\n","epoch 2/10, step: 160/500.0: loss = 0.00399, acc = 100.00\n","epoch 2/10, step: 170/500.0: loss = 0.00407, acc = 100.00\n","epoch 2/10, step: 180/500.0: loss = 0.02652, acc = 98.44\n","epoch 2/10, step: 190/500.0: loss = 0.00699, acc = 100.00\n","epoch 2/10, step: 200/500.0: loss = 0.05121, acc = 96.88\n","epoch 2/10, step: 210/500.0: loss = 0.00090, acc = 100.00\n","epoch 2/10, step: 220/500.0: loss = 0.00206, acc = 100.00\n","epoch 2/10, step: 230/500.0: loss = 0.00050, acc = 100.00\n","epoch 2/10, step: 240/500.0: loss = 0.00585, acc = 100.00\n","epoch 2/10, step: 250/500.0: loss = 0.00740, acc = 100.00\n","epoch 2/10, step: 260/500.0: loss = 0.00174, acc = 100.00\n","epoch 2/10, step: 270/500.0: loss = 0.00183, acc = 100.00\n","epoch 2/10, step: 280/500.0: loss = 0.03560, acc = 98.44\n","epoch 2/10, step: 290/500.0: loss = 0.00337, acc = 100.00\n","epoch 2/10, step: 300/500.0: loss = 0.00083, acc = 100.00\n","epoch 2/10, step: 310/500.0: loss = 0.02240, acc = 98.44\n","epoch 2/10, step: 320/500.0: loss = 0.01418, acc = 100.00\n","epoch 2/10, step: 330/500.0: loss = 0.00274, acc = 100.00\n","epoch 2/10, step: 340/500.0: loss = 0.02716, acc = 98.44\n","epoch 2/10, step: 350/500.0: loss = 0.01008, acc = 100.00\n","epoch 2/10, step: 360/500.0: loss = 0.00125, acc = 100.00\n","epoch 2/10, step: 370/500.0: loss = 0.00078, acc = 100.00\n","epoch 2/10, step: 380/500.0: loss = 0.01626, acc = 98.44\n","epoch 2/10, step: 390/500.0: loss = 0.00143, acc = 100.00\n","epoch 2/10, step: 400/500.0: loss = 0.00405, acc = 100.00\n","epoch 2/10, step: 410/500.0: loss = 0.00255, acc = 100.00\n","epoch 2/10, step: 420/500.0: loss = 0.00456, acc = 100.00\n","epoch 2/10, step: 430/500.0: loss = 0.00134, acc = 100.00\n","epoch 2/10, step: 440/500.0: loss = 0.00047, acc = 100.00\n","epoch 2/10, step: 450/500.0: loss = 0.03980, acc = 96.88\n","epoch 2/10, step: 460/500.0: loss = 0.00032, acc = 100.00\n","epoch 2/10, step: 470/500.0: loss = 0.00036, acc = 100.00\n","epoch 2/10, step: 480/500.0: loss = 0.00227, acc = 100.00\n","epoch 2/10, step: 490/500.0: loss = 0.01818, acc = 98.44\n","epoch 2/10, step: 500/500.0: loss = 0.00048, acc = 100.00\n","epoch 2/10, val accuracy = 99.29%. Correct 7943 out of 8000 samples\n","epoch 3/10, step: 10/500.0: loss = 0.00387, acc = 100.00\n","epoch 3/10, step: 20/500.0: loss = 0.00372, acc = 100.00\n","epoch 3/10, step: 30/500.0: loss = 0.00356, acc = 100.00\n","epoch 3/10, step: 40/500.0: loss = 0.00244, acc = 100.00\n","epoch 3/10, step: 50/500.0: loss = 0.00443, acc = 100.00\n","epoch 3/10, step: 60/500.0: loss = 0.01694, acc = 100.00\n","epoch 3/10, step: 70/500.0: loss = 0.00089, acc = 100.00\n","epoch 3/10, step: 80/500.0: loss = 0.02385, acc = 98.44\n","epoch 3/10, step: 90/500.0: loss = 0.00445, acc = 100.00\n","epoch 3/10, step: 100/500.0: loss = 0.03015, acc = 98.44\n","epoch 3/10, step: 110/500.0: loss = 0.00052, acc = 100.00\n","epoch 3/10, step: 120/500.0: loss = 0.00146, acc = 100.00\n","epoch 3/10, step: 130/500.0: loss = 0.01358, acc = 98.44\n","epoch 3/10, step: 140/500.0: loss = 0.00077, acc = 100.00\n","epoch 3/10, step: 150/500.0: loss = 0.00239, acc = 100.00\n","epoch 3/10, step: 160/500.0: loss = 0.00186, acc = 100.00\n","epoch 3/10, step: 170/500.0: loss = 0.00293, acc = 100.00\n","epoch 3/10, step: 180/500.0: loss = 0.00101, acc = 100.00\n","epoch 3/10, step: 190/500.0: loss = 0.00195, acc = 100.00\n","epoch 3/10, step: 200/500.0: loss = 0.00371, acc = 100.00\n","epoch 3/10, step: 210/500.0: loss = 0.00185, acc = 100.00\n","epoch 3/10, step: 220/500.0: loss = 0.00185, acc = 100.00\n","epoch 3/10, step: 230/500.0: loss = 0.00174, acc = 100.00\n","epoch 3/10, step: 240/500.0: loss = 0.00960, acc = 100.00\n","epoch 3/10, step: 250/500.0: loss = 0.00090, acc = 100.00\n","epoch 3/10, step: 260/500.0: loss = 0.00150, acc = 100.00\n","epoch 3/10, step: 270/500.0: loss = 0.00020, acc = 100.00\n","epoch 3/10, step: 280/500.0: loss = 0.00183, acc = 100.00\n","epoch 3/10, step: 290/500.0: loss = 0.00069, acc = 100.00\n","epoch 3/10, step: 300/500.0: loss = 0.01097, acc = 100.00\n","epoch 3/10, step: 310/500.0: loss = 0.00090, acc = 100.00\n","epoch 3/10, step: 320/500.0: loss = 0.01354, acc = 98.44\n","epoch 3/10, step: 330/500.0: loss = 0.01452, acc = 98.44\n","epoch 3/10, step: 340/500.0: loss = 0.00676, acc = 100.00\n","epoch 3/10, step: 350/500.0: loss = 0.00121, acc = 100.00\n","epoch 3/10, step: 360/500.0: loss = 0.00061, acc = 100.00\n","epoch 3/10, step: 370/500.0: loss = 0.00538, acc = 100.00\n","epoch 3/10, step: 380/500.0: loss = 0.01613, acc = 98.44\n","epoch 3/10, step: 390/500.0: loss = 0.00189, acc = 100.00\n","epoch 3/10, step: 400/500.0: loss = 0.00726, acc = 100.00\n","epoch 3/10, step: 410/500.0: loss = 0.00154, acc = 100.00\n","epoch 3/10, step: 420/500.0: loss = 0.00270, acc = 100.00\n","epoch 3/10, step: 430/500.0: loss = 0.00049, acc = 100.00\n","epoch 3/10, step: 440/500.0: loss = 0.00042, acc = 100.00\n","epoch 3/10, step: 450/500.0: loss = 0.00235, acc = 100.00\n","epoch 3/10, step: 460/500.0: loss = 0.00020, acc = 100.00\n","epoch 3/10, step: 470/500.0: loss = 0.00492, acc = 100.00\n","epoch 3/10, step: 480/500.0: loss = 0.00030, acc = 100.00\n","epoch 3/10, step: 490/500.0: loss = 0.01491, acc = 98.44\n","epoch 3/10, step: 500/500.0: loss = 0.00515, acc = 100.00\n","epoch 3/10, val accuracy = 99.38%. Correct 7950 out of 8000 samples\n","epoch 4/10, step: 10/500.0: loss = 0.00056, acc = 100.00\n","epoch 4/10, step: 20/500.0: loss = 0.00052, acc = 100.00\n","epoch 4/10, step: 30/500.0: loss = 0.04977, acc = 98.44\n","epoch 4/10, step: 40/500.0: loss = 0.00231, acc = 100.00\n","epoch 4/10, step: 50/500.0: loss = 0.00255, acc = 100.00\n","epoch 4/10, step: 60/500.0: loss = 0.00042, acc = 100.00\n","epoch 4/10, step: 70/500.0: loss = 0.00025, acc = 100.00\n","epoch 4/10, step: 80/500.0: loss = 0.00045, acc = 100.00\n","epoch 4/10, step: 90/500.0: loss = 0.00186, acc = 100.00\n","epoch 4/10, step: 100/500.0: loss = 0.00014, acc = 100.00\n","epoch 4/10, step: 110/500.0: loss = 0.00044, acc = 100.00\n","epoch 4/10, step: 120/500.0: loss = 0.00013, acc = 100.00\n","epoch 4/10, step: 130/500.0: loss = 0.00021, acc = 100.00\n","epoch 4/10, step: 140/500.0: loss = 0.00251, acc = 100.00\n","epoch 4/10, step: 150/500.0: loss = 0.00277, acc = 100.00\n","epoch 4/10, step: 160/500.0: loss = 0.00032, acc = 100.00\n","epoch 4/10, step: 170/500.0: loss = 0.00319, acc = 100.00\n","epoch 4/10, step: 180/500.0: loss = 0.00040, acc = 100.00\n","epoch 4/10, step: 190/500.0: loss = 0.07533, acc = 96.88\n","epoch 4/10, step: 200/500.0: loss = 0.00577, acc = 100.00\n","epoch 4/10, step: 210/500.0: loss = 0.00060, acc = 100.00\n","epoch 4/10, step: 220/500.0: loss = 0.02674, acc = 96.88\n","epoch 4/10, step: 230/500.0: loss = 0.00122, acc = 100.00\n","epoch 4/10, step: 240/500.0: loss = 0.00044, acc = 100.00\n","epoch 4/10, step: 250/500.0: loss = 0.00104, acc = 100.00\n","epoch 4/10, step: 260/500.0: loss = 0.00059, acc = 100.00\n","epoch 4/10, step: 270/500.0: loss = 0.00034, acc = 100.00\n","epoch 4/10, step: 280/500.0: loss = 0.00258, acc = 100.00\n","epoch 4/10, step: 290/500.0: loss = 0.00881, acc = 100.00\n","epoch 4/10, step: 300/500.0: loss = 0.02966, acc = 98.44\n","epoch 4/10, step: 310/500.0: loss = 0.00021, acc = 100.00\n","epoch 4/10, step: 320/500.0: loss = 0.00688, acc = 100.00\n","epoch 4/10, step: 330/500.0: loss = 0.00147, acc = 100.00\n","epoch 4/10, step: 340/500.0: loss = 0.00040, acc = 100.00\n","epoch 4/10, step: 350/500.0: loss = 0.00009, acc = 100.00\n","epoch 4/10, step: 360/500.0: loss = 0.00063, acc = 100.00\n","epoch 4/10, step: 370/500.0: loss = 0.00038, acc = 100.00\n","epoch 4/10, step: 380/500.0: loss = 0.00335, acc = 100.00\n","epoch 4/10, step: 390/500.0: loss = 0.00032, acc = 100.00\n","epoch 4/10, step: 400/500.0: loss = 0.00272, acc = 100.00\n","epoch 4/10, step: 410/500.0: loss = 0.00318, acc = 100.00\n","epoch 4/10, step: 420/500.0: loss = 0.00594, acc = 100.00\n","epoch 4/10, step: 430/500.0: loss = 0.02301, acc = 98.44\n","epoch 4/10, step: 440/500.0: loss = 0.00050, acc = 100.00\n","epoch 4/10, step: 450/500.0: loss = 0.00375, acc = 100.00\n","epoch 4/10, step: 460/500.0: loss = 0.00065, acc = 100.00\n","epoch 4/10, step: 470/500.0: loss = 0.00050, acc = 100.00\n","epoch 4/10, step: 480/500.0: loss = 0.00025, acc = 100.00\n","epoch 4/10, step: 490/500.0: loss = 0.00040, acc = 100.00\n","epoch 4/10, step: 500/500.0: loss = 0.00499, acc = 100.00\n","epoch 4/10, val accuracy = 99.38%. Correct 7950 out of 8000 samples\n","epoch 5/10, step: 10/500.0: loss = 0.00694, acc = 100.00\n","epoch 5/10, step: 20/500.0: loss = 0.00198, acc = 100.00\n","epoch 5/10, step: 30/500.0: loss = 0.00326, acc = 100.00\n","epoch 5/10, step: 40/500.0: loss = 0.00034, acc = 100.00\n","epoch 5/10, step: 50/500.0: loss = 0.00347, acc = 100.00\n","epoch 5/10, step: 60/500.0: loss = 0.00106, acc = 100.00\n","epoch 5/10, step: 70/500.0: loss = 0.00037, acc = 100.00\n","epoch 5/10, step: 80/500.0: loss = 0.00040, acc = 100.00\n","epoch 5/10, step: 90/500.0: loss = 0.00305, acc = 100.00\n","epoch 5/10, step: 100/500.0: loss = 0.00014, acc = 100.00\n","epoch 5/10, step: 110/500.0: loss = 0.00228, acc = 100.00\n","epoch 5/10, step: 120/500.0: loss = 0.02523, acc = 98.44\n","epoch 5/10, step: 130/500.0: loss = 0.00073, acc = 100.00\n","epoch 5/10, step: 140/500.0: loss = 0.00415, acc = 100.00\n","epoch 5/10, step: 150/500.0: loss = 0.00381, acc = 100.00\n","epoch 5/10, step: 160/500.0: loss = 0.00279, acc = 100.00\n","epoch 5/10, step: 170/500.0: loss = 0.00062, acc = 100.00\n","epoch 5/10, step: 180/500.0: loss = 0.00259, acc = 100.00\n","epoch 5/10, step: 190/500.0: loss = 0.01644, acc = 98.44\n","epoch 5/10, step: 200/500.0: loss = 0.00066, acc = 100.00\n","epoch 5/10, step: 210/500.0: loss = 0.00059, acc = 100.00\n","epoch 5/10, step: 220/500.0: loss = 0.00039, acc = 100.00\n","epoch 5/10, step: 230/500.0: loss = 0.00121, acc = 100.00\n","epoch 5/10, step: 240/500.0: loss = 0.00117, acc = 100.00\n","epoch 5/10, step: 250/500.0: loss = 0.00906, acc = 100.00\n","epoch 5/10, step: 260/500.0: loss = 0.00572, acc = 100.00\n","epoch 5/10, step: 270/500.0: loss = 0.00006, acc = 100.00\n","epoch 5/10, step: 280/500.0: loss = 0.00030, acc = 100.00\n","epoch 5/10, step: 290/500.0: loss = 0.00048, acc = 100.00\n","epoch 5/10, step: 300/500.0: loss = 0.00005, acc = 100.00\n","epoch 5/10, step: 310/500.0: loss = 0.00011, acc = 100.00\n","epoch 5/10, step: 320/500.0: loss = 0.00193, acc = 100.00\n","epoch 5/10, step: 330/500.0: loss = 0.00067, acc = 100.00\n","epoch 5/10, step: 340/500.0: loss = 0.00031, acc = 100.00\n","epoch 5/10, step: 350/500.0: loss = 0.00017, acc = 100.00\n","epoch 5/10, step: 360/500.0: loss = 0.00054, acc = 100.00\n","epoch 5/10, step: 370/500.0: loss = 0.00021, acc = 100.00\n","epoch 5/10, step: 380/500.0: loss = 0.00009, acc = 100.00\n","epoch 5/10, step: 390/500.0: loss = 0.00216, acc = 100.00\n","epoch 5/10, step: 400/500.0: loss = 0.01476, acc = 98.44\n","epoch 5/10, step: 410/500.0: loss = 0.00362, acc = 100.00\n","epoch 5/10, step: 420/500.0: loss = 0.00107, acc = 100.00\n","epoch 5/10, step: 430/500.0: loss = 0.07672, acc = 98.44\n","epoch 5/10, step: 440/500.0: loss = 0.02136, acc = 98.44\n","epoch 5/10, step: 450/500.0: loss = 0.00104, acc = 100.00\n","epoch 5/10, step: 460/500.0: loss = 0.00036, acc = 100.00\n","epoch 5/10, step: 470/500.0: loss = 0.00121, acc = 100.00\n","epoch 5/10, step: 480/500.0: loss = 0.00103, acc = 100.00\n","epoch 5/10, step: 490/500.0: loss = 0.00019, acc = 100.00\n","epoch 5/10, step: 500/500.0: loss = 0.00010, acc = 100.00\n","epoch 5/10, val accuracy = 99.66%. Correct 7973 out of 8000 samples\n","epoch 6/10, step: 10/500.0: loss = 0.00050, acc = 100.00\n","epoch 6/10, step: 20/500.0: loss = 0.00010, acc = 100.00\n","epoch 6/10, step: 30/500.0: loss = 0.00017, acc = 100.00\n","epoch 6/10, step: 40/500.0: loss = 0.00039, acc = 100.00\n","epoch 6/10, step: 50/500.0: loss = 0.00005, acc = 100.00\n","epoch 6/10, step: 60/500.0: loss = 0.00005, acc = 100.00\n","epoch 6/10, step: 70/500.0: loss = 0.00150, acc = 100.00\n","epoch 6/10, step: 80/500.0: loss = 0.00024, acc = 100.00\n","epoch 6/10, step: 90/500.0: loss = 0.00007, acc = 100.00\n","epoch 6/10, step: 100/500.0: loss = 0.00046, acc = 100.00\n","epoch 6/10, step: 110/500.0: loss = 0.00005, acc = 100.00\n","epoch 6/10, step: 120/500.0: loss = 0.00016, acc = 100.00\n","epoch 6/10, step: 130/500.0: loss = 0.00010, acc = 100.00\n","epoch 6/10, step: 140/500.0: loss = 0.00011, acc = 100.00\n","epoch 6/10, step: 150/500.0: loss = 0.00013, acc = 100.00\n","epoch 6/10, step: 160/500.0: loss = 0.00010, acc = 100.00\n","epoch 6/10, step: 170/500.0: loss = 0.00461, acc = 100.00\n","epoch 6/10, step: 180/500.0: loss = 0.00087, acc = 100.00\n","epoch 6/10, step: 190/500.0: loss = 0.00072, acc = 100.00\n","epoch 6/10, step: 200/500.0: loss = 0.00036, acc = 100.00\n","epoch 6/10, step: 210/500.0: loss = 0.00032, acc = 100.00\n","epoch 6/10, step: 220/500.0: loss = 0.00311, acc = 100.00\n","epoch 6/10, step: 230/500.0: loss = 0.00001, acc = 100.00\n","epoch 6/10, step: 240/500.0: loss = 0.00046, acc = 100.00\n","epoch 6/10, step: 250/500.0: loss = 0.00013, acc = 100.00\n","epoch 6/10, step: 260/500.0: loss = 0.07317, acc = 98.44\n","epoch 6/10, step: 270/500.0: loss = 0.00004, acc = 100.00\n","epoch 6/10, step: 280/500.0: loss = 0.00027, acc = 100.00\n","epoch 6/10, step: 290/500.0: loss = 0.00266, acc = 100.00\n","epoch 6/10, step: 300/500.0: loss = 0.00025, acc = 100.00\n","epoch 6/10, step: 310/500.0: loss = 0.00127, acc = 100.00\n","epoch 6/10, step: 320/500.0: loss = 0.00046, acc = 100.00\n","epoch 6/10, step: 330/500.0: loss = 0.00011, acc = 100.00\n","epoch 6/10, step: 340/500.0: loss = 0.00535, acc = 100.00\n","epoch 6/10, step: 350/500.0: loss = 0.00415, acc = 100.00\n","epoch 6/10, step: 360/500.0: loss = 0.01257, acc = 98.44\n","epoch 6/10, step: 370/500.0: loss = 0.00034, acc = 100.00\n","epoch 6/10, step: 380/500.0: loss = 0.00659, acc = 100.00\n","epoch 6/10, step: 390/500.0: loss = 0.00052, acc = 100.00\n","epoch 6/10, step: 400/500.0: loss = 0.00030, acc = 100.00\n","epoch 6/10, step: 410/500.0: loss = 0.00009, acc = 100.00\n","epoch 6/10, step: 420/500.0: loss = 0.00154, acc = 100.00\n","epoch 6/10, step: 430/500.0: loss = 0.00008, acc = 100.00\n","epoch 6/10, step: 440/500.0: loss = 0.00042, acc = 100.00\n","epoch 6/10, step: 450/500.0: loss = 0.00084, acc = 100.00\n","epoch 6/10, step: 460/500.0: loss = 0.00163, acc = 100.00\n","epoch 6/10, step: 470/500.0: loss = 0.00019, acc = 100.00\n","epoch 6/10, step: 480/500.0: loss = 0.00158, acc = 100.00\n","epoch 6/10, step: 490/500.0: loss = 0.00039, acc = 100.00\n","epoch 6/10, step: 500/500.0: loss = 0.01014, acc = 100.00\n","epoch 6/10, val accuracy = 98.61%. Correct 7889 out of 8000 samples\n","epoch 7/10, step: 10/500.0: loss = 0.00028, acc = 100.00\n","epoch 7/10, step: 20/500.0: loss = 0.00860, acc = 100.00\n","epoch 7/10, step: 30/500.0: loss = 0.00010, acc = 100.00\n","epoch 7/10, step: 40/500.0: loss = 0.00047, acc = 100.00\n","epoch 7/10, step: 50/500.0: loss = 0.04146, acc = 98.44\n","epoch 7/10, step: 60/500.0: loss = 0.00428, acc = 100.00\n","epoch 7/10, step: 70/500.0: loss = 0.00029, acc = 100.00\n","epoch 7/10, step: 80/500.0: loss = 0.01336, acc = 98.44\n","epoch 7/10, step: 90/500.0: loss = 0.00133, acc = 100.00\n","epoch 7/10, step: 100/500.0: loss = 0.00007, acc = 100.00\n","epoch 7/10, step: 110/500.0: loss = 0.00006, acc = 100.00\n","epoch 7/10, step: 120/500.0: loss = 0.00040, acc = 100.00\n","epoch 7/10, step: 130/500.0: loss = 0.01187, acc = 100.00\n","epoch 7/10, step: 140/500.0: loss = 0.00012, acc = 100.00\n","epoch 7/10, step: 150/500.0: loss = 0.00029, acc = 100.00\n","epoch 7/10, step: 160/500.0: loss = 0.00005, acc = 100.00\n","epoch 7/10, step: 170/500.0: loss = 0.00056, acc = 100.00\n","epoch 7/10, step: 180/500.0: loss = 0.00050, acc = 100.00\n","epoch 7/10, step: 190/500.0: loss = 0.00045, acc = 100.00\n","epoch 7/10, step: 200/500.0: loss = 0.02117, acc = 98.44\n","epoch 7/10, step: 210/500.0: loss = 0.00342, acc = 100.00\n","epoch 7/10, step: 220/500.0: loss = 0.00009, acc = 100.00\n","epoch 7/10, step: 230/500.0: loss = 0.00015, acc = 100.00\n","epoch 7/10, step: 240/500.0: loss = 0.00041, acc = 100.00\n","epoch 7/10, step: 250/500.0: loss = 0.00015, acc = 100.00\n","epoch 7/10, step: 260/500.0: loss = 0.00036, acc = 100.00\n","epoch 7/10, step: 270/500.0: loss = 0.00050, acc = 100.00\n","epoch 7/10, step: 280/500.0: loss = 0.00159, acc = 100.00\n","epoch 7/10, step: 290/500.0: loss = 0.02437, acc = 98.44\n","epoch 7/10, step: 300/500.0: loss = 0.00075, acc = 100.00\n","epoch 7/10, step: 310/500.0: loss = 0.00005, acc = 100.00\n","epoch 7/10, step: 320/500.0: loss = 0.00450, acc = 100.00\n","epoch 7/10, step: 330/500.0: loss = 0.00057, acc = 100.00\n","epoch 7/10, step: 340/500.0: loss = 0.00091, acc = 100.00\n","epoch 7/10, step: 350/500.0: loss = 0.00016, acc = 100.00\n","epoch 7/10, step: 360/500.0: loss = 0.00028, acc = 100.00\n","epoch 7/10, step: 370/500.0: loss = 0.00025, acc = 100.00\n","epoch 7/10, step: 380/500.0: loss = 0.00012, acc = 100.00\n","epoch 7/10, step: 390/500.0: loss = 0.01852, acc = 98.44\n","epoch 7/10, step: 400/500.0: loss = 0.00079, acc = 100.00\n","epoch 7/10, step: 410/500.0: loss = 0.00029, acc = 100.00\n","epoch 7/10, step: 420/500.0: loss = 0.00040, acc = 100.00\n","epoch 7/10, step: 430/500.0: loss = 0.00002, acc = 100.00\n","epoch 7/10, step: 440/500.0: loss = 0.00081, acc = 100.00\n","epoch 7/10, step: 450/500.0: loss = 0.00173, acc = 100.00\n","epoch 7/10, step: 460/500.0: loss = 0.00022, acc = 100.00\n","epoch 7/10, step: 470/500.0: loss = 0.00006, acc = 100.00\n","epoch 7/10, step: 480/500.0: loss = 0.00042, acc = 100.00\n","epoch 7/10, step: 490/500.0: loss = 0.00004, acc = 100.00\n","epoch 7/10, step: 500/500.0: loss = 0.00020, acc = 100.00\n","epoch 7/10, val accuracy = 99.44%. Correct 7955 out of 8000 samples\n","epoch 8/10, step: 10/500.0: loss = 0.00049, acc = 100.00\n","epoch 8/10, step: 20/500.0: loss = 0.00001, acc = 100.00\n","epoch 8/10, step: 30/500.0: loss = 0.00009, acc = 100.00\n","epoch 8/10, step: 40/500.0: loss = 0.00224, acc = 100.00\n","epoch 8/10, step: 50/500.0: loss = 0.01175, acc = 98.44\n","epoch 8/10, step: 60/500.0: loss = 0.00042, acc = 100.00\n","epoch 8/10, step: 70/500.0: loss = 0.00008, acc = 100.00\n","epoch 8/10, step: 80/500.0: loss = 0.00036, acc = 100.00\n","epoch 8/10, step: 90/500.0: loss = 0.00307, acc = 100.00\n","epoch 8/10, step: 100/500.0: loss = 0.00013, acc = 100.00\n","epoch 8/10, step: 110/500.0: loss = 0.00019, acc = 100.00\n","epoch 8/10, step: 120/500.0: loss = 0.00008, acc = 100.00\n","epoch 8/10, step: 130/500.0: loss = 0.00310, acc = 100.00\n","epoch 8/10, step: 140/500.0: loss = 0.00016, acc = 100.00\n","epoch 8/10, step: 150/500.0: loss = 0.00014, acc = 100.00\n","epoch 8/10, step: 160/500.0: loss = 0.01912, acc = 98.44\n","epoch 8/10, step: 170/500.0: loss = 0.00043, acc = 100.00\n","epoch 8/10, step: 180/500.0: loss = 0.00013, acc = 100.00\n","epoch 8/10, step: 190/500.0: loss = 0.00011, acc = 100.00\n","epoch 8/10, step: 200/500.0: loss = 0.00327, acc = 100.00\n","epoch 8/10, step: 210/500.0: loss = 0.00007, acc = 100.00\n","epoch 8/10, step: 220/500.0: loss = 0.01465, acc = 100.00\n","epoch 8/10, step: 230/500.0: loss = 0.00018, acc = 100.00\n","epoch 8/10, step: 240/500.0: loss = 0.00487, acc = 100.00\n","epoch 8/10, step: 250/500.0: loss = 0.00058, acc = 100.00\n","epoch 8/10, step: 260/500.0: loss = 0.00009, acc = 100.00\n","epoch 8/10, step: 270/500.0: loss = 0.00009, acc = 100.00\n","epoch 8/10, step: 280/500.0: loss = 0.00048, acc = 100.00\n","epoch 8/10, step: 290/500.0: loss = 0.00125, acc = 100.00\n","epoch 8/10, step: 300/500.0: loss = 0.00422, acc = 100.00\n","epoch 8/10, step: 310/500.0: loss = 0.00088, acc = 100.00\n","epoch 8/10, step: 320/500.0: loss = 0.00018, acc = 100.00\n","epoch 8/10, step: 330/500.0: loss = 0.00397, acc = 100.00\n","epoch 8/10, step: 340/500.0: loss = 0.00008, acc = 100.00\n","epoch 8/10, step: 350/500.0: loss = 0.00003, acc = 100.00\n","epoch 8/10, step: 360/500.0: loss = 0.00068, acc = 100.00\n","epoch 8/10, step: 370/500.0: loss = 0.01015, acc = 100.00\n","epoch 8/10, step: 380/500.0: loss = 0.00022, acc = 100.00\n","epoch 8/10, step: 390/500.0: loss = 0.00126, acc = 100.00\n","epoch 8/10, step: 400/500.0: loss = 0.00267, acc = 100.00\n","epoch 8/10, step: 410/500.0: loss = 0.00225, acc = 100.00\n","epoch 8/10, step: 420/500.0: loss = 0.00449, acc = 100.00\n","epoch 8/10, step: 430/500.0: loss = 0.00017, acc = 100.00\n","epoch 8/10, step: 440/500.0: loss = 0.00043, acc = 100.00\n","epoch 8/10, step: 450/500.0: loss = 0.00350, acc = 100.00\n","epoch 8/10, step: 460/500.0: loss = 0.00010, acc = 100.00\n","epoch 8/10, step: 470/500.0: loss = 0.00062, acc = 100.00\n","epoch 8/10, step: 480/500.0: loss = 0.00217, acc = 100.00\n","epoch 8/10, step: 490/500.0: loss = 0.00019, acc = 100.00\n","epoch 8/10, step: 500/500.0: loss = 0.00019, acc = 100.00\n","epoch 8/10, val accuracy = 99.30%. Correct 7944 out of 8000 samples\n","epoch 9/10, step: 10/500.0: loss = 0.00579, acc = 100.00\n","epoch 9/10, step: 20/500.0: loss = 0.00001, acc = 100.00\n","epoch 9/10, step: 30/500.0: loss = 0.00003, acc = 100.00\n","epoch 9/10, step: 40/500.0: loss = 0.00024, acc = 100.00\n","epoch 9/10, step: 50/500.0: loss = 0.00039, acc = 100.00\n","epoch 9/10, step: 60/500.0: loss = 0.00004, acc = 100.00\n","epoch 9/10, step: 70/500.0: loss = 0.00061, acc = 100.00\n","epoch 9/10, step: 80/500.0: loss = 0.00042, acc = 100.00\n","epoch 9/10, step: 90/500.0: loss = 0.01749, acc = 98.44\n","epoch 9/10, step: 100/500.0: loss = 0.00010, acc = 100.00\n","epoch 9/10, step: 110/500.0: loss = 0.00101, acc = 100.00\n","epoch 9/10, step: 120/500.0: loss = 0.00003, acc = 100.00\n","epoch 9/10, step: 130/500.0: loss = 0.00023, acc = 100.00\n","epoch 9/10, step: 140/500.0: loss = 0.00014, acc = 100.00\n","epoch 9/10, step: 150/500.0: loss = 0.00087, acc = 100.00\n","epoch 9/10, step: 160/500.0: loss = 0.01484, acc = 98.44\n","epoch 9/10, step: 170/500.0: loss = 0.00327, acc = 100.00\n","epoch 9/10, step: 180/500.0: loss = 0.00014, acc = 100.00\n","epoch 9/10, step: 190/500.0: loss = 0.03542, acc = 98.44\n","epoch 9/10, step: 200/500.0: loss = 0.00140, acc = 100.00\n","epoch 9/10, step: 210/500.0: loss = 0.00009, acc = 100.00\n","epoch 9/10, step: 220/500.0: loss = 0.00077, acc = 100.00\n","epoch 9/10, step: 230/500.0: loss = 0.00054, acc = 100.00\n","epoch 9/10, step: 240/500.0: loss = 0.00025, acc = 100.00\n","epoch 9/10, step: 250/500.0: loss = 0.00048, acc = 100.00\n","epoch 9/10, step: 260/500.0: loss = 0.00061, acc = 100.00\n","epoch 9/10, step: 270/500.0: loss = 0.00002, acc = 100.00\n","epoch 9/10, step: 280/500.0: loss = 0.00022, acc = 100.00\n","epoch 9/10, step: 290/500.0: loss = 0.00004, acc = 100.00\n","epoch 9/10, step: 300/500.0: loss = 0.00012, acc = 100.00\n","epoch 9/10, step: 310/500.0: loss = 0.00009, acc = 100.00\n","epoch 9/10, step: 320/500.0: loss = 0.00117, acc = 100.00\n","epoch 9/10, step: 330/500.0: loss = 0.00017, acc = 100.00\n","epoch 9/10, step: 340/500.0: loss = 0.00006, acc = 100.00\n","epoch 9/10, step: 350/500.0: loss = 0.01349, acc = 98.44\n","epoch 9/10, step: 360/500.0: loss = 0.00004, acc = 100.00\n","epoch 9/10, step: 370/500.0: loss = 0.00765, acc = 100.00\n","epoch 9/10, step: 380/500.0: loss = 0.00266, acc = 100.00\n","epoch 9/10, step: 390/500.0: loss = 0.00032, acc = 100.00\n","epoch 9/10, step: 400/500.0: loss = 0.00010, acc = 100.00\n","epoch 9/10, step: 410/500.0: loss = 0.00011, acc = 100.00\n","epoch 9/10, step: 420/500.0: loss = 0.02657, acc = 98.44\n","epoch 9/10, step: 430/500.0: loss = 0.00050, acc = 100.00\n","epoch 9/10, step: 440/500.0: loss = 0.00068, acc = 100.00\n","epoch 9/10, step: 450/500.0: loss = 0.00026, acc = 100.00\n","epoch 9/10, step: 460/500.0: loss = 0.00016, acc = 100.00\n","epoch 9/10, step: 470/500.0: loss = 0.00002, acc = 100.00\n","epoch 9/10, step: 480/500.0: loss = 0.06002, acc = 98.44\n","epoch 9/10, step: 490/500.0: loss = 0.00025, acc = 100.00\n","epoch 9/10, step: 500/500.0: loss = 0.00014, acc = 100.00\n","epoch 9/10, val accuracy = 99.55%. Correct 7964 out of 8000 samples\n","epoch 10/10, step: 10/500.0: loss = 0.00005, acc = 100.00\n","epoch 10/10, step: 20/500.0: loss = 0.00002, acc = 100.00\n","epoch 10/10, step: 30/500.0: loss = 0.00011, acc = 100.00\n","epoch 10/10, step: 40/500.0: loss = 0.00215, acc = 100.00\n","epoch 10/10, step: 50/500.0: loss = 0.00009, acc = 100.00\n","epoch 10/10, step: 60/500.0: loss = 0.00006, acc = 100.00\n","epoch 10/10, step: 70/500.0: loss = 0.00003, acc = 100.00\n","epoch 10/10, step: 80/500.0: loss = 0.00086, acc = 100.00\n","epoch 10/10, step: 90/500.0: loss = 0.00156, acc = 100.00\n","epoch 10/10, step: 100/500.0: loss = 0.00091, acc = 100.00\n","epoch 10/10, step: 110/500.0: loss = 0.00151, acc = 100.00\n","epoch 10/10, step: 120/500.0: loss = 0.00016, acc = 100.00\n","epoch 10/10, step: 130/500.0: loss = 0.00009, acc = 100.00\n","epoch 10/10, step: 140/500.0: loss = 0.00007, acc = 100.00\n","epoch 10/10, step: 150/500.0: loss = 0.00104, acc = 100.00\n","epoch 10/10, step: 160/500.0: loss = 0.00064, acc = 100.00\n","epoch 10/10, step: 170/500.0: loss = 0.00255, acc = 100.00\n","epoch 10/10, step: 180/500.0: loss = 0.00090, acc = 100.00\n","epoch 10/10, step: 190/500.0: loss = 0.01553, acc = 98.44\n","epoch 10/10, step: 200/500.0: loss = 0.00325, acc = 100.00\n","epoch 10/10, step: 210/500.0: loss = 0.00026, acc = 100.00\n","epoch 10/10, step: 220/500.0: loss = 0.00220, acc = 100.00\n","epoch 10/10, step: 230/500.0: loss = 0.00014, acc = 100.00\n","epoch 10/10, step: 240/500.0: loss = 0.00020, acc = 100.00\n","epoch 10/10, step: 250/500.0: loss = 0.00876, acc = 100.00\n","epoch 10/10, step: 260/500.0: loss = 0.00012, acc = 100.00\n","epoch 10/10, step: 270/500.0: loss = 0.00002, acc = 100.00\n","epoch 10/10, step: 280/500.0: loss = 0.00442, acc = 100.00\n","epoch 10/10, step: 290/500.0: loss = 0.00014, acc = 100.00\n","epoch 10/10, step: 300/500.0: loss = 0.03257, acc = 98.44\n","epoch 10/10, step: 310/500.0: loss = 0.00046, acc = 100.00\n","epoch 10/10, step: 320/500.0: loss = 0.00012, acc = 100.00\n","epoch 10/10, step: 330/500.0: loss = 0.00001, acc = 100.00\n","epoch 10/10, step: 340/500.0: loss = 0.00964, acc = 100.00\n","epoch 10/10, step: 350/500.0: loss = 0.00002, acc = 100.00\n","epoch 10/10, step: 360/500.0: loss = 0.00012, acc = 100.00\n","epoch 10/10, step: 370/500.0: loss = 0.00168, acc = 100.00\n","epoch 10/10, step: 380/500.0: loss = 0.00009, acc = 100.00\n","epoch 10/10, step: 390/500.0: loss = 0.00008, acc = 100.00\n","epoch 10/10, step: 400/500.0: loss = 0.00001, acc = 100.00\n","epoch 10/10, step: 410/500.0: loss = 0.02232, acc = 98.44\n","epoch 10/10, step: 420/500.0: loss = 0.00018, acc = 100.00\n","epoch 10/10, step: 430/500.0: loss = 0.00002, acc = 100.00\n","epoch 10/10, step: 440/500.0: loss = 0.00006, acc = 100.00\n","epoch 10/10, step: 450/500.0: loss = 0.00060, acc = 100.00\n","epoch 10/10, step: 460/500.0: loss = 0.00002, acc = 100.00\n","epoch 10/10, step: 470/500.0: loss = 0.00193, acc = 100.00\n","epoch 10/10, step: 480/500.0: loss = 0.00025, acc = 100.00\n","epoch 10/10, step: 490/500.0: loss = 0.00021, acc = 100.00\n","epoch 10/10, step: 500/500.0: loss = 0.00001, acc = 100.00\n","epoch 10/10, val accuracy = 99.50%. Correct 7960 out of 8000 samples\n"]}],"source":["\n","# torch.cuda.empty_cache()\n","\n","for epoch in range(num_epoch):\n","    epoch_avg_loss = 0\n","    for i, (imgs, labels) in enumerate(train_loader):\n","        imgs = transform_train(imgs.to(device))\n","        labels = labels.to(device)\n","\n","        labels_hat = model(imgs)\n","        n_corrects = (labels_hat.argmax(axis=1) == labels).sum().item()\n","        loss_value = criterion(labels_hat, labels)\n","        loss_value.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        epoch_avg_loss += loss_value.item()\n","\n","        accuracy = (n_corrects / labels.size(0)) * 100\n","\n","        if (i+1) % 10 == 0:\n","            print(f'epoch {epoch + 1}/{num_epoch}, step: {i + 1}/{train_size/BATCH_SIZE}: loss = {loss_value:.5f}, acc = {accuracy:.2f}')\n","\n","    epoch_loss_history.append(epoch_avg_loss / len(train_loader))\n","\n","    with torch.no_grad():\n","        correct = 0\n","        samples = 0\n","\n","        for i, (images, labels) in enumerate(test_loader):\n","            images = transform_test(images.to(device))\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predictions = outputs.max(1)\n","            correct += (predictions == labels).sum()\n","            samples += predictions.size(0)\n","\n","        accuracy = float(correct) / float(samples) * 100\n","        epoch_acc_history.append(accuracy)\n","\n","        print(f\"epoch {epoch + 1}/{num_epoch}, val accuracy = {accuracy:.2f}%. Correct {correct} out of {samples} samples\")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708130927124,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"32nueb0q7t3r","outputId":"bc4afd34-aed6-4100-a779-6f19284e91e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.09181079315766692, 0.013283439244900365, 0.008672975107532692, 0.007014932877420506, 0.005685827836548924, 0.0036459875853506675, 0.0032127326549361897, 0.005143991610404555, 0.003569534302269858, 0.003389765918469493]\n"]}],"source":["print(epoch_loss_history)\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708130927124,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"CBXssxex7t3r","outputId":"5bf8a4d6-2f98-467c-bf99-ce5208896748"},"outputs":[{"name":"stdout","output_type":"stream","text":["[98.32499999999999, 99.2875, 99.375, 99.375, 99.6625, 98.6125, 99.4375, 99.3, 99.55000000000001, 99.5]\n"]}],"source":["print(epoch_acc_history)\n"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":983,"status":"ok","timestamp":1708130928099,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"nx8FHBd37t3r"},"outputs":[],"source":["with open('/content/drive/MyDrive/res/history/effnet_hurricane_W4_xy_s1_loss_history.txt', \"w\") as f:\n","    for item in epoch_loss_history:\n","        f.write(f'{item:.5f}\\n')"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":447,"status":"ok","timestamp":1708130928545,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"zAo7wYLD7t3r"},"outputs":[],"source":["with open('/content/drive/MyDrive/res/history/effnet_hurricane_W4_xy_s1_acc_history.txt', \"w\") as f:\n","    for item in epoch_acc_history:\n","        f.write(f'{item:.5f}\\n')"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":676,"status":"ok","timestamp":1708130935498,"user":{"displayName":"Yevhenii Trochun","userId":"17711385059759821998"},"user_tz":-120},"id":"adozxn5Z7t3r"},"outputs":[],"source":["torch.save(model, '/content/drive/MyDrive/res/effnet_hurricane_W4_xy_s1.pth')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"vscode":{"interpreter":{"hash":"294ee4d107f05ff1d3e2c0a05728a96d0532b46a53afc266da718b2bb9e6a9d0"}}},"nbformat":4,"nbformat_minor":0}
